{
 "cells": [
  {
   "cell_type": "raw",
   "id": "fe2e1b31-0750-4f60-b293-a961bbe6490a",
   "metadata": {},
   "source": [
    "## Session 1: NLP Basics - Text Preprocessing for Security Logs\n",
    "\n",
    "In networking/security, NLP helps analyze logs (e.g., \"Unauthorized access from IP 192.168.1.1\") for threats. We'll preprocess text using NLTK: tokenize, remove stopwords, stem/lemmatize.\n",
    "\n",
    "**Domain Example**: Classify AD login logs as \"normal\" or \"suspicious\" based on text patterns (e.g., \"failed login\" stems to \"fail login\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac5635b-ef8a-4eeb-8922-8012a0f565a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk import pos_tag, download\n",
    "import re\n",
    "\n",
    "# Download NLTK data (run once)\n",
    "download('punkt')\n",
    "download('stopwords')\n",
    "download('wordnet')\n",
    "download('averaged_perceptron_tagger')\n",
    "\n",
    "# Sample security log data (simulate AD/Sitecore logs)\n",
    "data = {\n",
    "    'log_text': [\n",
    "        \"Unauthorized access attempt from IP 192.168.1.1 on Active Directory server\",\n",
    "        \"Successful login for user admin on Sitecore portal\",\n",
    "        \"Failed authentication from unknown IP 8.8.8.8 with multiple retries\",\n",
    "        \"Normal traffic from internal network to firewall\",\n",
    "        \"Suspicious packet drop in UDP connection from remote server\",\n",
    "        \"User query on Sitecore CMS: search for sensitive documents\",\n",
    "        \"Brute force attack detected on AD domain controller\"\n",
    "    ]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "print(\"Raw Logs:\")\n",
    "print(df)\n",
    "\n",
    "# Function for tokenization\n",
    "def tokenize_text(text):\n",
    "    # Convert to lowercase and remove special characters\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text.lower())\n",
    "    # Tokenize into words\n",
    "    tokens = word_tokenize(text)\n",
    "    return tokens\n",
    "\n",
    "# Apply tokenization\n",
    "df['tokens'] = df['log_text'].apply(tokenize_text)\n",
    "print(\"\\nTokenized Logs:\")\n",
    "print(df[['log_text', 'tokens']])\n",
    "''' Explanation: Tokenization splits text into words, e.g., \n",
    "\"Unauthorized access\" -> ['unauthorized', 'access']. Useful for parsing security logs'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebbfea6-5945-45af-aa0e-f286fb8a44ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stopwords removal\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def remove_stopwords(tokens):\n",
    "    filtered_tokens = [word for word in tokens if word not in stop_words]\n",
    "    return filtered_tokens\n",
    "\n",
    "df['filtered_tokens'] = df['tokens'].apply(remove_stopwords)\n",
    "print(\"Logs After Stopword Removal:\")\n",
    "print(df[['log_text', 'filtered_tokens']])\n",
    "# Explanation: Removes common words like \"from\", \"on\" to focus on key terms like \"unauthorized\", \"failed\". In security, this highlights threats like \"attack\".\n",
    "\n",
    "# Stemming (Porter Stemmer)\n",
    "stemmer = PorterStemmer()\n",
    "def stem_tokens(tokens):\n",
    "    stemmed = [stemmer.stem(word) for word in tokens]\n",
    "    return stemmed\n",
    "\n",
    "df['stemmed'] = df['filtered_tokens'].apply(stem_tokens)\n",
    "print(\"\\nStemmed Logs:\")\n",
    "print(df[['log_text', 'stemmed']])\n",
    "# Explanation: Stemming reduces words to roots, e.g., \"attempts\" -> \"attempt\". Good for matching variants in logs (e.g., \"failed\" and \"failure\").\n",
    "\n",
    "# Lemmatization (more accurate than stemming)\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def lemmatize_tokens(tokens):\n",
    "    # POS tagging for better lemmatization\n",
    "    tagged = pos_tag(tokens)\n",
    "    lemmatized = [lemmatizer.lemmatize(word, pos='v' if tag.startswith('V') else 'n') for word, tag in tagged]\n",
    "    return lemmatized\n",
    "\n",
    "df['lemmatized'] = df['filtered_tokens'].apply(lemmatize_tokens)\n",
    "print(\"\\nLemmatized Logs:\")\n",
    "print(df[['log_text', 'lemmatized']])\n",
    "# Explanation: Lemmatization returns base forms, e.g., \"accesses\" -> \"access\". Better for domain-specific text like AD logs where context matters."
   ]
  },
  {
   "cell_type": "raw",
   "id": "15d1166a-5437-4ced-8171-34fe5616c8cd",
   "metadata": {},
   "source": [
    "## Session 2: Advanced NLP - Vectorization and Basic Tasks\n",
    "\n",
    "Building on preprocessing, we'll vectorize text (convert to numbers for ML) using TF-IDF, perform sentiment analysis on security logs, and topic modeling with LDA for grouping threats.\n",
    "\n",
    "**Domain Example**: Vectorize AD logs to classify sentiment (positive for \"successful login\", negative for \"failed authentication\") or discover topics like \"brute force\" vs. \"normal access\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7252087-06ca-45e7-9142-c6b4a132d3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorization with TF-IDF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Prepare text (use lemmatized tokens joined back to strings)\n",
    "df['processed_text'] = df['lemmatized'].apply(' '.join)\n",
    "\n",
    "# TF-IDF Vectorizer (max_features=50 to keep simple)\n",
    "vectorizer = TfidfVectorizer(max_features=50, stop_words='english')\n",
    "X_tfidf = vectorizer.fit_transform(df['processed_text'])\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "print(\"TF-IDF Features (Top 10):\", feature_names[:10])\n",
    "print(\"TF-IDF Matrix Shape:\", X_tfidf.shape)\n",
    "# Explanation: TF-IDF converts text to sparse matrix; high scores for rare terms like \"brute\" in logs. Useful for ML input in security analysis.\n",
    "\n",
    "# Display TF-IDF scores for first log\n",
    "first_log_scores = X_tfidf[0].toarray().flatten()\n",
    "top_terms = sorted(zip(feature_names, first_log_scores), key=lambda x: x[1], reverse=True)[:5]\n",
    "print(\"\\nTop Terms for First Log:\", top_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ff6a51-ca58-439e-89bb-7bae13972188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment Analysis with VADER (pre-trained for social/domain text)\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "download('vader_lexicon')\n",
    "\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "df['sentiment'] = df['processed_text'].apply(lambda x: sia.polarity_scores(x)['compound'])\n",
    "print(\"Sentiment Scores:\")\n",
    "print(df[['log_text', 'sentiment']])\n",
    "# Explanation: VADER scores text from -1 (negative) to 1 (positive). E.g., \n",
    "# \"failed authentication\" = negative, flagging suspicious AD logs.\n",
    "\n",
    "# Topic Modeling with LDA (Gensim)\n",
    "from gensim import corpora, models\n",
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "# Prepare corpus from lemmatized tokens\n",
    "tokenized_docs = df['lemmatized'].tolist()\n",
    "dictionary = corpora.Dictionary(tokenized_docs)\n",
    "corpus = [dictionary.doc2bow(doc) for doc in tokenized_docs]\n",
    "\n",
    "# LDA model (num_topics=2 for simplicity)\n",
    "lda_model = models.LdaModel(corpus, num_topics=2, id2word=dictionary, passes=10)\n",
    "topics = lda_model.print_topics(num_words=3)\n",
    "print(\"LDA Topics:\")\n",
    "for topic in topics:\n",
    "    print(topic)\n",
    "# Explanation: LDA discovers topics (e.g., Topic 0: \"access unauthorized ip\" for threats). \n",
    "# Useful for grouping Sitecore logs into \"normal\" vs \"suspicious\"."
   ]
  },
  {
   "cell_type": "raw",
   "id": "b20745ae-b071-4103-8fa9-52a57799c31f",
   "metadata": {},
   "source": [
    "### Hands-On: Analyze New Logs\n",
    "Add 3 new security logs to `data`. Vectorize, compute sentiment, and fit LDA. Discuss: How do topics reveal patterns like \"brute force\" in AD logs?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7108a5c7-9f94-4604-8900-09e10472e277",
   "metadata": {},
   "source": [
    "## Session 3: Generative AI Basics - Prompt Engineering with Ollama\n",
    "\n",
    "Generative AI (Gen AI) uses models like Llama2 or Mistral (via Ollama for local, free inference) to generate text. We'll focus on prompt engineering: crafting inputs to get useful outputs.\n",
    "\n",
    "**Domain Example**: Generate security report summaries from logs (e.g., \"Summarize threat from IP 192.168.1.1\") or AD user recommendations (e.g., \"Suggest fixes for failed login\").\n",
    "\n",
    "**Setup**: Install Ollama (`curl -fsSL https://ollama.com/install.sh | sh`), pull model (`ollama pull mistral`). No API keys needed—runs locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c091a8-f759-4963-b726-64ea627e2e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Ollama client (run in terminal: pip install ollama)\n",
    "import ollama\n",
    "\n",
    "# Test Ollama with Mistral (or Llama2)\n",
    "response = ollama.chat(model='mistral', messages=[{'role': 'user', 'content': 'Hello, what is NLP?'}])\n",
    "print(\"Basic Response:\", response['message']['content'])\n",
    "# Explanation: Ollama runs Mistral locally. 'chat' sends prompts; \n",
    "# 'messages' simulates conversation. Safe for domain-sensitive data (no cloud).\n",
    "\n",
    "# Prompt Engineering Basics\n",
    "prompts = [\n",
    "    \"What is NLP?\",  # Basic prompt\n",
    "    \"Explain NLP in 3 sentences for a security analyst.\",  # Specific role\n",
    "    \"As a network security expert, explain how NLP can analyze intrusion logs in Active Directory.\"  \n",
    "    # Domain-specific\n",
    "]\n",
    "\n",
    "for i, prompt in enumerate(prompts, 1):\n",
    "    response = ollama.chat(model='mistral', messages=[{'role': 'user', 'content': prompt}])\n",
    "    print(f\"\\nPrompt {i}: {prompt}\")\n",
    "    print(\"Response:\", response['message']['content'][:200] + \"...\" if len(response['message']['content']) > 200 else response['message']['content'])\n",
    "# Explanation: Better prompts (specific, role-based) yield relevant outputs. For security, \n",
    "    #add \"confidential\" to prompts for ethical handling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9efedae-d5f6-4245-a54d-2e5c6101bacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Domain-Specific Prompt: Security Log Analysis\n",
    "log_example = \"Failed login from IP 192.168.1.1 on AD server at 2025-09-18 10:00:00\"\n",
    "prompt = f\"As a cybersecurity analyst, analyze this Active Directory log and suggest 3 mitigation steps: {log_example}\"\n",
    "response = ollama.chat(model='mistral', messages=[{'role': 'user', 'content': prompt}])\n",
    "print(\"Security Log Analysis:\")\n",
    "print(response['message']['content'])\n",
    "# Explanation: Prompt engineering tailors Gen AI for domain tasks like log triage in Sitecore/AD. Use 'system' role for consistent personas.\n",
    "\n",
    "# Chain Prompts (Conversation)\n",
    "messages = [\n",
    "    {'role': 'system', 'content': 'You are a network security expert.'},\n",
    "    {'role': 'user', 'content': 'What is a common threat in Sitecore deployments?'},\n",
    "    {'role': 'assistant', 'content': response['message']['content'][:100] + \"...\"}  # Simulate previous response\n",
    "]\n",
    "chain_response = ollama.chat(model='mistral', messages=messages)\n",
    "print(\"\\nChained Prompt Response:\")\n",
    "print(chain_response['message']['content'])\n",
    "# Explanation: Chain prompts for multi-turn interactions, e.g., refining threat analysis in security audits."
   ]
  },
  {
   "cell_type": "raw",
   "id": "019bcd8e-3816-46e8-bf40-9028e32cea18",
   "metadata": {},
   "source": [
    "### Hands-On: Prompt Engineering for Your Domain\n",
    "Create 3 prompts for Gen AI: (1) Basic, (2) Role-specific (e.g., \"As an AD admin...\"), (3) Domain task (e.g., \"Summarize Sitecore log for threats\"). Test with Ollama and compare outputs."
   ]
  },
  {
   "cell_type": "raw",
   "id": "2e2beee9-a371-487a-8fa7-eb24c5c8f8a1",
   "metadata": {},
   "source": [
    "## Session 4: Gen AI Hands-On - Chaining and Fine-Tuning Simulation with Ollama\n",
    "\n",
    "We'll chain prompts for multi-step tasks (e.g., log analysis + recommendation) and simulate fine-tuning by curating domain-specific examples for Mistral.\n",
    "\n",
    "**Domain Example**: Chain to \"Analyze AD log → Generate report → Suggest fixes\" for security workflows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5877446a-9cb4-4ae0-8194-1d99d25fc575",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chaining Prompts for Multi-Step Task\n",
    "# Example: Security Workflow - Log Analysis Chain\n",
    "messages = [\n",
    "    {'role': 'system', 'content': 'You are a Gen AI assistant for network security.'},\n",
    "    {'role': 'user', 'content': 'Step 1: Analyze this Sitecore log: \"Error in user authentication from IP 10.0.0.5\".'}\n",
    "]\n",
    "response1 = ollama.chat(model='mistral', messages=messages)\n",
    "print(\"Step 1 Response:\", response1['message']['content'])\n",
    "\n",
    "# Chain Step 2\n",
    "messages.append({'role': 'assistant', 'content': response1['message']['content']})\n",
    "messages.append({'role': 'user', 'content': 'Step 2: Based on analysis, suggest 2 fixes.'})\n",
    "response2 = ollama.chat(model='mistral', messages=messages)\n",
    "print(\"\\nStep 2 Response:\", response2['message']['content'])\n",
    "# Explanation: Chaining builds workflows, e.g., log triage in AD/Sitecore. Append to 'messages' for context.\n",
    "\n",
    "# Multi-Step Chain for Security Report\n",
    "full_chain = [\n",
    "    {'role': 'system', 'content': 'You are a security analyst using Gen AI.'},\n",
    "    {'role': 'user', 'content': 'Generate a threat report from this AD log: \"Multiple failed logins from external IP\". Include risk level and mitigation.'}\n",
    "]\n",
    "report_response = ollama.chat(model='mistral', messages=full_chain)\n",
    "print(\"\\nFull Chain Report:\")\n",
    "print(report_response['message']['content'])\n",
    "# Explanation: Single prompt for chained reasoning, useful for automated security reports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a70a8cf-7797-416c-a5c7-fb17566db333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate Fine-Tuning with Few-Shot Prompting (No Actual Training - Ollama Local)\n",
    "# Use examples to \"fine-tune\" behavior for domain (e.g., security classification)\n",
    "few_shot_prompt = \"\"\"\n",
    "You are a fine-tuned Gen AI for classifying network threats. Examples:\n",
    "Input: Failed login from IP 192.168.1.1\n",
    "Output: Threat: Brute Force | Risk: Medium | Mitigation: Block IP\n",
    "\n",
    "Input: Normal traffic on port 80\n",
    "Output: Threat: None | Risk: Low | Mitigation: Monitor\n",
    "\n",
    "Classify this: Suspicious UDP packets to Sitecore server.\n",
    "\"\"\"\n",
    "response_fs = ollama.chat(model='mistral', messages=[{'role': 'user', 'content': few_shot_prompt}])\n",
    "print(\"Few-Shot Classification:\")\n",
    "print(response_fs['message']['content'])\n",
    "# Explanation: Few-shot prompting simulates fine-tuning by providing examples. For local Ollama, this adapts Mistral to domain without training data/credits.\n",
    "\n",
    "# Hands-On Extension: Create Your Own Few-Shot\n",
    "# Add 2 more examples (e.g., AD log) to few_shot_prompt and re-run. Discuss: How does this \"fine-tune\" for Sitecore threats?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "39ff279e-a033-4259-a5ae-a9e14445dde3",
   "metadata": {},
   "source": [
    "### Hands-On: Build a Security Chain\n",
    "Chain 3 prompts: (1) Analyze log, (2) Classify threat, (3) Generate mitigation. Test with your own AD/Sitecore log example. Compare Mistral vs. Llama2 (`ollama pull llama2`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb650f0-8045-4e99-b70c-6ba418e9bad9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
